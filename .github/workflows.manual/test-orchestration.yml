name: Test Orchestration

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    - cron: '0 2 * * 1'  # Weekly comprehensive test run
  workflow_dispatch:
    inputs:
      test_level:
        description: 'Test level to run'
        required: true
        default: 'full'
        type: choice
        options:
          - smoke
          - unit
          - integration
          - e2e
          - full
          - performance
          - security

env:
  CARGO_TERM_COLOR: always
  RUST_BACKTRACE: full
  TEST_RESULTS_DIR: test-results

jobs:
  # Test orchestration coordinator
  test-orchestrator:
    name: Test Orchestration Coordinator
    runs-on: ubuntu-latest
    outputs:
      test-matrix: ${{ steps.generate-matrix.outputs.matrix }}
      test-level: ${{ steps.determine-level.outputs.level }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Determine test level
        id: determine-level
        run: |
          if [[ "${{ github.event_name }}" == "schedule" ]]; then
            echo "level=full" >> $GITHUB_OUTPUT
          elif [[ "${{ github.event.inputs.test_level }}" != "" ]]; then
            echo "level=${{ github.event.inputs.test_level }}" >> $GITHUB_OUTPUT
          elif [[ "${{ github.event_name }}" == "pull_request" ]]; then
            echo "level=integration" >> $GITHUB_OUTPUT
          else
            echo "level=unit" >> $GITHUB_OUTPUT
          fi

      - name: Generate test matrix
        id: generate-matrix
        run: |
          case "${{ steps.determine-level.outputs.level }}" in
            smoke)
              MATRIX='["smoke"]'
              ;;
            unit)
              MATRIX='["unit", "lint", "format"]'
              ;;
            integration)
              MATRIX='["unit", "integration", "lint", "format", "coverage"]'
              ;;
            e2e)
              MATRIX='["unit", "integration", "e2e", "lint", "format", "coverage"]'
              ;;
            performance)
              MATRIX='["unit", "performance", "benchmark"]'
              ;;
            security)
              MATRIX='["unit", "security", "fuzz", "audit"]'
              ;;
            full|*)
              MATRIX='["unit", "integration", "e2e", "performance", "security", "lint", "format", "coverage", "fuzz", "audit", "mutation"]'
              ;;
          esac
          echo "matrix=$MATRIX" >> $GITHUB_OUTPUT

  # Unit tests
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: test-orchestrator
    if: contains(needs.test-orchestrator.outputs.test-matrix, 'unit')

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Rust
        uses: actions-rust-lang/setup-rust-toolchain@v1
        with:
          toolchain: stable
          components: rustfmt, clippy

      - name: Cache dependencies
        uses: Swatinem/rust-cache@v2

      - name: Create test results directory
        run: mkdir -p ${{ env.TEST_RESULTS_DIR }}

      - name: Run unit tests
        run: |
          cargo test --lib --all-features \
            --format json \
            --report-time \
            | tee ${{ env.TEST_RESULTS_DIR }}/unit-tests.json

      - name: Run doc tests
        run: |
          cargo test --doc \
            --format json \
            | tee ${{ env.TEST_RESULTS_DIR }}/doc-tests.json

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: unit-test-results
          path: ${{ env.TEST_RESULTS_DIR }}/

  # Integration tests
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [test-orchestrator, unit-tests]
    if: contains(needs.test-orchestrator.outputs.test-matrix, 'integration')

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Rust
        uses: actions-rust-lang/setup-rust-toolchain@v1

      - name: Cache dependencies
        uses: Swatinem/rust-cache@v2

      - name: Setup test environment
        run: |
          ./tests/environments/manage.sh setup local

      - name: Create test results directory
        run: mkdir -p ${{ env.TEST_RESULTS_DIR }}

      - name: Run integration tests
        run: |
          cargo test --test 'integration_*' --all-features \
            --format json \
            --report-time \
            | tee ${{ env.TEST_RESULTS_DIR }}/integration-tests.json

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: integration-test-results
          path: ${{ env.TEST_RESULTS_DIR }}/

      - name: Cleanup environment
        if: always()
        run: |
          ./tests/environments/manage.sh teardown local

  # E2E tests
  e2e-tests:
    name: E2E Tests
    runs-on: ubuntu-latest
    needs: [test-orchestrator, integration-tests]
    if: contains(needs.test-orchestrator.outputs.test-matrix, 'e2e')

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Rust
        uses: actions-rust-lang/setup-rust-toolchain@v1

      - name: Cache dependencies
        uses: Swatinem/rust-cache@v2

      - name: Setup staging environment
        run: |
          ./tests/environments/manage.sh setup staging

      - name: Build binary
        run: cargo build --release

      - name: Create test results directory
        run: mkdir -p ${{ env.TEST_RESULTS_DIR }}

      - name: Run E2E tests
        run: |
          cargo test --test 'e2e_*' --all-features \
            --format json \
            --report-time \
            | tee ${{ env.TEST_RESULTS_DIR }}/e2e-tests.json

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-test-results
          path: ${{ env.TEST_RESULTS_DIR }}/

      - name: Cleanup environment
        if: always()
        run: |
          ./tests/environments/manage.sh teardown staging

  # Performance tests
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    needs: test-orchestrator
    if: contains(needs.test-orchestrator.outputs.test-matrix, 'performance')

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Rust
        uses: actions-rust-lang/setup-rust-toolchain@v1

      - name: Cache dependencies
        uses: Swatinem/rust-cache@v2

      - name: Create test results directory
        run: mkdir -p ${{ env.TEST_RESULTS_DIR }}

      - name: Run benchmarks
        run: |
          cargo bench --no-fail-fast \
            | tee ${{ env.TEST_RESULTS_DIR }}/benchmarks.txt

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-test-results
          path: ${{ env.TEST_RESULTS_DIR }}/

  # Security tests
  security-tests:
    name: Security Tests
    runs-on: ubuntu-latest
    needs: test-orchestrator
    if: contains(needs.test-orchestrator.outputs.test-matrix, 'security')

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Rust
        uses: actions-rust-lang/setup-rust-toolchain@v1

      - name: Cache dependencies
        uses: Swatinem/rust-cache@v2

      - name: Install cargo-audit
        run: cargo install cargo-audit

      - name: Create test results directory
        run: mkdir -p ${{ env.TEST_RESULTS_DIR }}

      - name: Run security audit
        run: |
          cargo audit \
            | tee ${{ env.TEST_RESULTS_DIR }}/security-audit.txt

      - name: Upload security results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: security-test-results
          path: ${{ env.TEST_RESULTS_DIR }}/

  # Code quality checks
  quality-checks:
    name: Code Quality
    runs-on: ubuntu-latest
    needs: test-orchestrator
    if: contains(needs.test-orchestrator.outputs.test-matrix, 'lint') || contains(needs.test-orchestrator.outputs.test-matrix, 'format')

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Rust
        uses: actions-rust-lang/setup-rust-toolchain@v1
        with:
          components: rustfmt, clippy

      - name: Create test results directory
        run: mkdir -p ${{ env.TEST_RESULTS_DIR }}

      - name: Check formatting
        run: |
          cargo fmt --all -- --check \
            | tee ${{ env.TEST_RESULTS_DIR }}/format-check.txt || true

      - name: Run Clippy
        run: |
          cargo clippy --all-features --all-targets -- -D warnings \
            | tee ${{ env.TEST_RESULTS_DIR }}/clippy-results.txt || true

      - name: Upload quality results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: quality-check-results
          path: ${{ env.TEST_RESULTS_DIR }}/

  # Coverage analysis
  coverage:
    name: Code Coverage
    runs-on: ubuntu-latest
    needs: [test-orchestrator, unit-tests, integration-tests]
    if: contains(needs.test-orchestrator.outputs.test-matrix, 'coverage')

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Rust
        uses: actions-rust-lang/setup-rust-toolchain@v1

      - name: Install cargo-tarpaulin
        run: cargo install cargo-tarpaulin

      - name: Cache dependencies
        uses: Swatinem/rust-cache@v2

      - name: Generate coverage
        run: |
          cargo tarpaulin --config tarpaulin.toml --verbose \
            --out Lcov \
            --output-dir coverage

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage/lcov.info
          fail_ci_if_error: false

      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report
          path: coverage/

  # Fuzz tests
  fuzz-tests:
    name: Fuzz Tests
    runs-on: ubuntu-latest
    needs: test-orchestrator
    if: contains(needs.test-orchestrator.outputs.test-matrix, 'fuzz')

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Rust nightly
        uses: actions-rust-lang/setup-rust-toolchain@v1
        with:
          toolchain: nightly

      - name: Install cargo-fuzz
        run: cargo install cargo-fuzz

      - name: Create test results directory
        run: mkdir -p ${{ env.TEST_RESULTS_DIR }}

      - name: Run fuzz tests
        run: |
          cargo fuzz list | while read target; do
            timeout 300 cargo fuzz run "$target" -- -max_total_time=300 || true
          done | tee ${{ env.TEST_RESULTS_DIR }}/fuzz-results.txt

      - name: Upload fuzz artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: fuzz-test-results
          path: |
            ${{ env.TEST_RESULTS_DIR }}/
            fuzz/artifacts/

  # Mutation tests
  mutation-tests:
    name: Mutation Tests
    runs-on: ubuntu-latest
    needs: test-orchestrator
    if: contains(needs.test-orchestrator.outputs.test-matrix, 'mutation')

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Rust
        uses: actions-rust-lang/setup-rust-toolchain@v1

      - name: Install cargo-mutants
        run: cargo install cargo-mutants

      - name: Create test results directory
        run: mkdir -p ${{ env.TEST_RESULTS_DIR }}

      - name: Run mutation tests
        run: |
          cargo mutants --timeout 300 --jobs 4 \
            | tee ${{ env.TEST_RESULTS_DIR }}/mutation-results.txt

      - name: Upload mutation report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: mutation-test-results
          path: |
            ${{ env.TEST_RESULTS_DIR }}/
            mutants.out/

  # Test results aggregator
  test-results:
    name: Test Results Summary
    runs-on: ubuntu-latest
    needs: [test-orchestrator, unit-tests, integration-tests, e2e-tests, performance-tests, security-tests, quality-checks, coverage, fuzz-tests, mutation-tests]
    if: always()

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download all test results
        uses: actions/download-artifact@v4
        with:
          path: all-test-results

      - name: Generate test summary
        run: |
          echo "# Test Execution Summary" > test-summary.md
          echo "" >> test-summary.md
          echo "## Test Level: ${{ needs.test-orchestrator.outputs.test-level }}" >> test-summary.md
          echo "" >> test-summary.md
          echo "## Results by Test Type" >> test-summary.md
          echo "" >> test-summary.md

          # Process each test result directory
          for dir in all-test-results/*/; do
            if [[ -d "$dir" ]]; then
              test_type=$(basename "$dir")
              echo "### $test_type" >> test-summary.md
              echo "" >> test-summary.md

              # Count results if available
              if [[ -f "$dir/test-results.txt" ]]; then
                passed=$(grep -c "PASS" "$dir/test-results.txt" || echo "0")
                failed=$(grep -c "FAIL" "$dir/test-results.txt" || echo "0")
                echo "- Passed: $passed" >> test-summary.md
                echo "- Failed: $failed" >> test-summary.md
              else
                echo "- Results: Available in artifacts" >> test-summary.md
              fi
              echo "" >> test-summary.md
            fi
          done

          # Overall status
          if [[ "${{ needs.test-orchestrator.result }}" == "success" ]]; then
            echo "## ✅ All Tests Passed" >> test-summary.md
          else
            echo "## ❌ Some Tests Failed" >> test-summary.md
          fi

          cat test-summary.md

      - name: Upload test summary
        uses: actions/upload-artifact@v4
        with:
          name: test-summary
          path: test-summary.md

      - name: Comment PR with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const summary = fs.readFileSync('test-summary.md', 'utf8');

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });
