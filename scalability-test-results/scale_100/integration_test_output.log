warning: function `create_temp_file` is never used
  --> tests/input_validation_security_tests.rs:12:8
   |
12 |     fn create_temp_file(content: &str) -> Result<String, Box<dyn std::error::Error>> {
   |        ^^^^^^^^^^^^^^^^
   |
   = note: `#[warn(dead_code)]` (part of `#[warn(unused)]`) on by default

warning: unused variable: `inference`
  --> tests/cold_start_inference_tests.rs:18:9
   |
18 |     let inference = ColdStartInference::new(&defaults);
   |         ^^^^^^^^^ help: if this is intentional, prefix it with an underscore: `_inference`
   |
   = note: `#[warn(unused_variables)]` (part of `#[warn(unused)]`) on by default

warning: unused import: `std::collections::HashMap`
 --> tests/download_network_tests.rs:1:5
  |
1 | use std::collections::HashMap;
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^
  |
  = note: `#[warn(unused_imports)]` (part of `#[warn(unused)]`) on by default

warning: unused import: `std::process::Command`
 --> tests/download_network_tests.rs:5:5
  |
5 | use std::process::Command;
  |     ^^^^^^^^^^^^^^^^^^^^^

warning: function `golden_simple_dependency_graph` is never used
  --> tests/golden_mapping_tests.rs:40:4
   |
40 | fn golden_simple_dependency_graph() {
   |    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |
   = note: `#[warn(dead_code)]` (part of `#[warn(unused)]`) on by default

warning: use of deprecated associated function `assert_cmd::Command::cargo_bin`: incompatible with a custom cargo build-dir, see instead `cargo::cargo_bin_cmd!`
   --> tests/e2e_cli_tests.rs:133:28
    |
133 |     let mut cmd = Command::cargo_bin("costpilot").unwrap();
    |                            ^^^^^^^^^
    |
    = note: `#[warn(deprecated)]` on by default

warning: use of deprecated associated function `assert_cmd::Command::cargo_bin`: incompatible with a custom cargo build-dir, see instead `cargo::cargo_bin_cmd!`
   --> tests/e2e_cli_tests.rs:158:28
    |
158 |     let mut cmd = Command::cargo_bin("costpilot").unwrap();
    |                            ^^^^^^^^^

warning: use of deprecated associated function `assert_cmd::Command::cargo_bin`: incompatible with a custom cargo build-dir, see instead `cargo::cargo_bin_cmd!`
   --> tests/e2e_cli_tests.rs:181:28
    |
181 |     let mut cmd = Command::cargo_bin("costpilot").unwrap();
    |                            ^^^^^^^^^

warning: use of deprecated associated function `assert_cmd::Command::cargo_bin`: incompatible with a custom cargo build-dir, see instead `cargo::cargo_bin_cmd!`
   --> tests/e2e_cli_tests.rs:200:28
    |
200 |     let mut cmd = Command::cargo_bin("costpilot").unwrap();
    |                            ^^^^^^^^^

warning: use of deprecated associated function `assert_cmd::Command::cargo_bin`: incompatible with a custom cargo build-dir, see instead `cargo::cargo_bin_cmd!`
   --> tests/e2e_cli_tests.rs:223:28
    |
223 |     let mut cmd = Command::cargo_bin("costpilot").unwrap();
    |                            ^^^^^^^^^

warning: use of deprecated associated function `assert_cmd::Command::cargo_bin`: incompatible with a custom cargo build-dir, see instead `cargo::cargo_bin_cmd!`
   --> tests/e2e_cli_tests.rs:262:28
    |
262 |     let mut cmd = Command::cargo_bin("costpilot").unwrap();
    |                            ^^^^^^^^^

warning: use of deprecated associated function `assert_cmd::Command::cargo_bin`: incompatible with a custom cargo build-dir, see instead `cargo::cargo_bin_cmd!`
   --> tests/e2e_cli_tests.rs:282:28
    |
282 |     let mut cmd = Command::cargo_bin("costpilot").unwrap();
    |                            ^^^^^^^^^

warning: use of deprecated associated function `assert_cmd::Command::cargo_bin`: incompatible with a custom cargo build-dir, see instead `cargo::cargo_bin_cmd!`
   --> tests/e2e_cli_tests.rs:308:28
    |
308 |     let mut cmd = Command::cargo_bin("costpilot").unwrap();
    |                            ^^^^^^^^^

warning: use of deprecated associated function `assert_cmd::Command::cargo_bin`: incompatible with a custom cargo build-dir, see instead `cargo::cargo_bin_cmd!`
   --> tests/e2e_cli_tests.rs:330:28
    |
330 |     let mut cmd = Command::cargo_bin("costpilot").unwrap();
    |                            ^^^^^^^^^

warning: use of deprecated associated function `assert_cmd::Command::cargo_bin`: incompatible with a custom cargo build-dir, see instead `cargo::cargo_bin_cmd!`
   --> tests/e2e_cli_tests.rs:357:28
    |
357 |     let mut cmd = Command::cargo_bin("costpilot").unwrap();
    |                            ^^^^^^^^^

warning: use of deprecated associated function `assert_cmd::Command::cargo_bin`: incompatible with a custom cargo build-dir, see instead `cargo::cargo_bin_cmd!`
   --> tests/e2e_cli_tests.rs:375:28
    |
375 |     let mut cmd = Command::cargo_bin("costpilot").unwrap();
    |                            ^^^^^^^^^

warning: use of deprecated associated function `assert_cmd::Command::cargo_bin`: incompatible with a custom cargo build-dir, see instead `cargo::cargo_bin_cmd!`
   --> tests/e2e_cli_tests.rs:387:28
    |
387 |     let mut cmd = Command::cargo_bin("costpilot").unwrap();
    |                            ^^^^^^^^^

warning: use of deprecated associated function `assert_cmd::Command::cargo_bin`: incompatible with a custom cargo build-dir, see instead `cargo::cargo_bin_cmd!`
   --> tests/e2e_cli_tests.rs:405:28
    |
405 |     let mut cmd = Command::cargo_bin("costpilot").unwrap();
    |                            ^^^^^^^^^

warning: use of deprecated associated function `assert_cmd::Command::cargo_bin`: incompatible with a custom cargo build-dir, see instead `cargo::cargo_bin_cmd!`
   --> tests/e2e_cli_tests.rs:418:29
    |
418 |     let mut cmd1 = Command::cargo_bin("costpilot").unwrap();
    |                             ^^^^^^^^^

warning: use of deprecated associated function `assert_cmd::Command::cargo_bin`: incompatible with a custom cargo build-dir, see instead `cargo::cargo_bin_cmd!`
   --> tests/e2e_cli_tests.rs:424:29
    |
424 |     let mut cmd2 = Command::cargo_bin("costpilot").unwrap();
    |                             ^^^^^^^^^

warning: unused variable: `manager`
  --> tests/baseline_tests.rs:80:9
   |
80 |     let manager = BaselinesManager::from_config(config);
   |         ^^^^^^^ help: if this is intentional, prefix it with an underscore: `_manager`
   |
   = note: `#[warn(unused_variables)]` (part of `#[warn(unused)]`) on by default

warning: unused variable: `within_variance`
   --> tests/baseline_tests.rs:115:13
    |
115 |         let within_variance = variance <= baseline.acceptable_variance_percent;
    |             ^^^^^^^^^^^^^^^ help: if this is intentional, prefix it with an underscore: `_within_variance`

warning: unused variable: `variance`
   --> tests/baseline_tests.rs:293:9
    |
293 |     let variance =
    |         ^^^^^^^^ help: if this is intentional, prefix it with an underscore: `_variance`

warning: unused imports: `Signature` and `VerifyingKey`
 --> tests/license_issuer_integration_tests.rs:5:25
  |
5 |     use ed25519_dalek::{Signature, Verifier, VerifyingKey};
  |                         ^^^^^^^^^            ^^^^^^^^^^^^
  |
  = note: `#[warn(unused_imports)]` (part of `#[warn(unused)]`) on by default


running 9 tests
.........
test result: ok. 9 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.02s


running 12 tests
............
test result: ok. 12 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s


running 8 tests
........
test result: ok. 8 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.07s


running 54 tests
......................................................
test result: ok. 54 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s


running 7 tests
..License validation failed: Err("Rate limit exceeded. Try again later.")
.....
test result: ok. 7 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.01s


running 8 tests
........
test result: ok. 8 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s


running 10 tests
..........
test result: ok. 10 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s


running 18 tests
......proptest: FileFailurePersistence::SourceParallel set, but failed to find lib.rs or main.rs
.proptest: FileFailurePersistence::SourceParallel set, but failed to find lib.rs or main.rs
..proptest: FileFailurePersistence::SourceParallel set, but failed to find lib.rs or main.rs
.........
test result: ok. 18 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s


running 10 tests
..........
test result: ok. 10 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.01s


running 65 tests
.................................................................
test result: ok. 65 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.01s


running 8 tests
...Testing 1000 resources, plan size: 62943 bytes
.Processing time: 134.895Âµs
....
test result: ok. 8 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.08s


running 3 tests
...
test result: ok. 3 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s


running 39 tests
.......................................
test result: ok. 39 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.03s


running 90 tests
....................................................................................... 87/90
...
test result: ok. 90 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s


running 12 tests
........
thread 'test_telemetry_unhappy_paths' (411521) panicked at tests/comprehensive_path_tests.rs:312:53:
called `Result::unwrap()` on an `Err` value: NotPresent
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace
.. 10/12
test_telemetry_unhappy_paths --- FAILED
.
failures:

failures:
    test_telemetry_unhappy_paths

test result: FAILED. 11 passed; 1 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s

error: test failed, to rerun pass `--test comprehensive_path_tests`
shed in 0.00s


running 5 tests
.....
test result: ok. 5 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s


running 9 tests
.........
test result: ok. 9 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s


running 11 tests
..........test test_binary_installs_linux_architectures has been running for over 60 seconds
ARM64 target not installed, skipping ARM64 build test
.
test result: ok. 11 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 708.49s


running 93 tests
..........proptest: FileFailurePersistence::SourceParallel set, but failed to find lib.rs or main.rs
..................proptest: FileFailurePersistence::SourceParallel set, but failed to find lib.rs or main.rs
....proptest: FileFailurePersistence::SourceParallel set, but failed to find lib.rs or main.rs
...proptest: FileFailurePersistence::SourceParallel set, but failed to find lib.rs or main.rs
..Parsing Terraform plan JSON...
Terraform version: Some("1.0.0")
Format version: 1.1
Detected 0 resource changes
.................................................. 87/93
......
test result: ok. 93 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.02s


running 13 tests
.............
test result: ok. 13 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.02s


running 6 tests
......
test result: ok. 6 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s


running 6 tests
......
test result: ok. 6 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s


running 2 tests

thread 'test_artifact_parity_across_distribution_channels' (416126) panicked at tests/distributed_artifacts_tests.rs:50:5:
not yet implemented: Implement artifact parity test across distribution channels
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace

thread 'test_distributed_artifacts_match_tested_artifacts' (416127) panicked at tests/distributed_artifacts_tests.rs:24:5:
not yet implemented: Implement distributed artifacts matching test
test_artifact_parity_across_distribution_channels --- FAILED
test_distributed_artifacts_match_tested_artifacts --- FAILED

failures:

failures:
    test_artifact_parity_across_distribution_channels
    test_distributed_artifacts_match_tested_artifacts

test result: FAILED. 0 passed; 2 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s

error: test failed, to rerun pass `--test distributed_artifacts_tests`
